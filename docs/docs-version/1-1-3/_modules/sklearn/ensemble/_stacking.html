
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>sklearn.ensemble._stacking &#8212; sklearndf  documentation</title>
    
  <link rel="stylesheet" href="../../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/gamma.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/gamma.js"></script>
    <script src="../../../_static/js/versions.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main">
<div class="container-xl">

    <a class="navbar-brand" href="../../../index.html">
    
      <img src="../../../_static/gamma_sklearndf_logo.png" class="logo" alt="logo" />
    
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../getting_started/getting_started.html">Getting started</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../apidoc/sklearndf.html">API reference</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../tutorials.html">Tutorials</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../contribution_guide.html">Development Guidelines</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../faqs.html">FAQ</a>
        </li>
        
        <li class="nav-item ">
            <a class="nav-link" href="../../../release_notes.html">Release Notes</a>
        </li>
        
        
      </ul>


      

      <ul class="navbar-nav">
        
        
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
          <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">

    <div class="bd-toc-item active">
    
  
    <ul class="nav bd-sidenav">
        
        
        
        
        
        
        
        
        
        
        
        
        
      </ul>
  
  </nav>
          </div>
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
    </ul>
</nav>


              
          </div>
          

          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for sklearn.ensemble._stacking</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Stacking classifier and regressor.&quot;&quot;&quot;</span>

<span class="c1"># Authors: Guillaume Lemaitre &lt;g.lemaitre58@gmail.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sparse</span>

<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">ClassifierMixin</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">,</span> <span class="n">TransformerMixin</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">is_classifier</span><span class="p">,</span> <span class="n">is_regressor</span>
<span class="kn">from</span> <span class="nn">..exceptions</span> <span class="kn">import</span> <span class="n">NotFittedError</span>
<span class="kn">from</span> <span class="nn">..utils._estimator_html_repr</span> <span class="kn">import</span> <span class="n">_VisualBlock</span>

<span class="kn">from</span> <span class="nn">._base</span> <span class="kn">import</span> <span class="n">_fit_single_estimator</span>
<span class="kn">from</span> <span class="nn">._base</span> <span class="kn">import</span> <span class="n">_BaseHeterogeneousEnsemble</span>

<span class="kn">from</span> <span class="nn">..linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">..linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span>

<span class="kn">from</span> <span class="nn">..model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="kn">from</span> <span class="nn">..model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span>

<span class="kn">from</span> <span class="nn">..preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">Bunch</span>
<span class="kn">from</span> <span class="nn">..utils.metaestimators</span> <span class="kn">import</span> <span class="n">if_delegate_has_method</span>
<span class="kn">from</span> <span class="nn">..utils.multiclass</span> <span class="kn">import</span> <span class="n">check_classification_targets</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">check_is_fitted</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">column_or_1d</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">_deprecate_positional_args</span>


<span class="k">class</span> <span class="nc">_BaseStacking</span><span class="p">(</span><span class="n">TransformerMixin</span><span class="p">,</span> <span class="n">_BaseHeterogeneousEnsemble</span><span class="p">,</span>
                    <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for stacking method.&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">stack_method</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">passthrough</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator</span> <span class="o">=</span> <span class="n">final_estimator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_method</span> <span class="o">=</span> <span class="n">stack_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span> <span class="o">=</span> <span class="n">n_jobs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">passthrough</span> <span class="o">=</span> <span class="n">passthrough</span>

    <span class="k">def</span> <span class="nf">_clone_final_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">default</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_estimator</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">default</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_concatenate_predictions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Concatenate the predictions of each first layer learner and</span>
<span class="sd">        possibly the input dataset `X`.</span>

<span class="sd">        If `X` is sparse and `self.passthrough` is False, the output of</span>
<span class="sd">        `transform` will be dense (the predictions). If `X` is sparse</span>
<span class="sd">        and `self.passthrough` is True, the output of `transform` will</span>
<span class="sd">        be sparse.</span>

<span class="sd">        This helper is in charge of ensuring the predictions are 2D arrays and</span>
<span class="sd">        it will drop one of the probability column when using probabilities</span>
<span class="sd">        in the binary case. Indeed, the p(y|c=0) = 1 - p(y|c=1)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_meta</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">est_idx</span><span class="p">,</span> <span class="n">preds</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predictions</span><span class="p">):</span>
            <span class="c1"># case where the the estimator returned a 1D array</span>
            <span class="k">if</span> <span class="n">preds</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">X_meta</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_method_</span><span class="p">[</span><span class="n">est_idx</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;predict_proba&#39;</span> <span class="ow">and</span>
                        <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">):</span>
                    <span class="c1"># Remove the first column when using probabilities in</span>
                    <span class="c1"># binary classification because both features are perfectly</span>
                    <span class="c1"># collinear.</span>
                    <span class="n">X_meta</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">X_meta</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">passthrough</span><span class="p">:</span>
            <span class="n">X_meta</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">sparse</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">X_meta</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">X_meta</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_method_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">method</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">estimator</span> <span class="o">==</span> <span class="s1">&#39;drop&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s1">&#39;predict_proba&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">return</span> <span class="s1">&#39;predict_proba&#39;</span>
            <span class="k">elif</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s1">&#39;decision_function&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">return</span> <span class="s1">&#39;decision_function&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="s1">&#39;predict&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">method</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Underlying estimator </span><span class="si">{}</span><span class="s1"> does not implement &#39;</span>
                                 <span class="s1">&#39;the method </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">method</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">method</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the estimators.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where `n_samples` is the number of samples and</span>
<span class="sd">            `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            Target values.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,) or default=None</span>
<span class="sd">            Sample weights. If None, then samples are equally weighted.</span>
<span class="sd">            Note that this is supported only if all underlying estimators</span>
<span class="sd">            support sample weights.</span>

<span class="sd">            .. versionchanged:: 0.23</span>
<span class="sd">               when not None, `sample_weight` is passed to all underlying</span>
<span class="sd">               estimators</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># all_estimators contains all estimators, the one to be fitted and the</span>
        <span class="c1"># &#39;drop&#39; string.</span>
        <span class="n">names</span><span class="p">,</span> <span class="n">all_estimators</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_estimators</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_final_estimator</span><span class="p">()</span>

        <span class="n">stack_method</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_method</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_estimators</span><span class="p">)</span>

        <span class="c1"># Fit the base estimators on the whole training data. Those</span>
        <span class="c1"># base estimators will be used in transform, predict, and</span>
        <span class="c1"># predict_proba. They are exposed publicly.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="n">_fit_single_estimator</span><span class="p">)(</span><span class="n">clone</span><span class="p">(</span><span class="n">est</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">all_estimators</span> <span class="k">if</span> <span class="n">est</span> <span class="o">!=</span> <span class="s1">&#39;drop&#39;</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">named_estimators_</span> <span class="o">=</span> <span class="n">Bunch</span><span class="p">()</span>
        <span class="n">est_fitted_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">name_est</span><span class="p">,</span> <span class="n">org_est</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">all_estimators</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">org_est</span> <span class="o">!=</span> <span class="s1">&#39;drop&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">named_estimators_</span><span class="p">[</span><span class="n">name_est</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span>
                    <span class="n">est_fitted_idx</span><span class="p">]</span>
                <span class="n">est_fitted_idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">named_estimators_</span><span class="p">[</span><span class="n">name_est</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;drop&#39;</span>

        <span class="c1"># To train the meta-classifier using the most data as possible, we use</span>
        <span class="c1"># a cross-validation to obtain the output of the stacked estimators.</span>

        <span class="c1"># To ensure that the data provided to each estimator are the same, we</span>
        <span class="c1"># need to set the random state of the cv if there is one and we need to</span>
        <span class="c1"># take a copy.</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="n">is_classifier</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s1">&#39;random_state&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cv</span><span class="o">.</span><span class="n">random_state</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">cv</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">stack_method_</span> <span class="o">=</span> <span class="p">[</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_method_name</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">est</span><span class="p">,</span> <span class="n">meth</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">est</span><span class="p">,</span> <span class="n">meth</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">all_estimators</span><span class="p">,</span> <span class="n">stack_method</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">fit_params</span> <span class="o">=</span> <span class="p">({</span><span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="n">sample_weight</span><span class="p">}</span>
                      <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                      <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="n">cross_val_predict</span><span class="p">)(</span><span class="n">clone</span><span class="p">(</span><span class="n">est</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">cv</span><span class="p">),</span>
                                       <span class="n">method</span><span class="o">=</span><span class="n">meth</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
                                       <span class="n">fit_params</span><span class="o">=</span><span class="n">fit_params</span><span class="p">,</span>
                                       <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">est</span><span class="p">,</span> <span class="n">meth</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">all_estimators</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_method_</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">est</span> <span class="o">!=</span> <span class="s1">&#39;drop&#39;</span>
        <span class="p">)</span>

        <span class="c1"># Only not None or not &#39;drop&#39; estimators will be used in transform.</span>
        <span class="c1"># Remove the None from the method as well.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stack_method_</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">meth</span> <span class="k">for</span> <span class="p">(</span><span class="n">meth</span><span class="p">,</span> <span class="n">est</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stack_method_</span><span class="p">,</span> <span class="n">all_estimators</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">est</span> <span class="o">!=</span> <span class="s1">&#39;drop&#39;</span>
        <span class="p">]</span>

        <span class="n">X_meta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_concatenate_predictions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
        <span class="n">_fit_single_estimator</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="p">,</span> <span class="n">X_meta</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                              <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_features_in_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Number of features seen during :term:`fit`.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">NotFittedError</span> <span class="k">as</span> <span class="n">nfe</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> object has no attribute &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;n_features_in_&quot;</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">nfe</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">n_features_in_</span>

    <span class="k">def</span> <span class="nf">_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Concatenate and return the predictions of the estimators.&quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">meth</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">est</span><span class="p">,</span> <span class="n">meth</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stack_method_</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">est</span> <span class="o">!=</span> <span class="s1">&#39;drop&#39;</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_concatenate_predictions</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>

    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="s1">&#39;final_estimator_&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">predict_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict target for X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        **predict_params : dict of str -&gt; obj</span>
<span class="sd">            Parameters to the `predict` called by the `final_estimator`. Note</span>
<span class="sd">            that this may be used to return uncertainties from some estimators</span>
<span class="sd">            with `return_std` or `return_cov`. Be aware that it will only</span>
<span class="sd">            accounts for uncertainty in the final estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_pred : ndarray of shape (n_samples,) or (n_samples, n_output)</span>
<span class="sd">            Predicted targets.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="o">**</span><span class="n">predict_params</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sk_visual_block_</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">final_estimator</span><span class="p">):</span>
        <span class="n">names</span><span class="p">,</span> <span class="n">estimators</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">estimators</span><span class="p">)</span>
        <span class="n">parallel</span> <span class="o">=</span> <span class="n">_VisualBlock</span><span class="p">(</span><span class="s1">&#39;parallel&#39;</span><span class="p">,</span> <span class="n">estimators</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">,</span>
                                <span class="n">dash_wrapped</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">serial</span> <span class="o">=</span> <span class="n">_VisualBlock</span><span class="p">(</span><span class="s1">&#39;serial&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">parallel</span><span class="p">,</span> <span class="n">final_estimator</span><span class="p">),</span>
                              <span class="n">dash_wrapped</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_VisualBlock</span><span class="p">(</span><span class="s1">&#39;serial&#39;</span><span class="p">,</span> <span class="p">[</span><span class="n">serial</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">StackingClassifier</span><span class="p">(</span><span class="n">ClassifierMixin</span><span class="p">,</span> <span class="n">_BaseStacking</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stack of estimators with a final classifier.</span>

<span class="sd">    Stacked generalization consists in stacking the output of individual</span>
<span class="sd">    estimator and use a classifier to compute the final prediction. Stacking</span>
<span class="sd">    allows to use the strength of each individual estimator by using their</span>
<span class="sd">    output as input of a final estimator.</span>

<span class="sd">    Note that `estimators_` are fitted on the full `X` while `final_estimator_`</span>
<span class="sd">    is trained using cross-validated predictions of the base estimators using</span>
<span class="sd">    `cross_val_predict`.</span>

<span class="sd">    .. versionadded:: 0.22</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;stacking&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimators : list of (str, estimator)</span>
<span class="sd">        Base estimators which will be stacked together. Each element of the</span>
<span class="sd">        list is defined as a tuple of string (i.e. name) and an estimator</span>
<span class="sd">        instance. An estimator can be set to &#39;drop&#39; using `set_params`.</span>

<span class="sd">    final_estimator : estimator, default=None</span>
<span class="sd">        A classifier which will be used to combine the base estimators.</span>
<span class="sd">        The default classifier is a `LogisticRegression`.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy used in</span>
<span class="sd">        `cross_val_predict` to train `final_estimator`. Possible inputs for</span>
<span class="sd">        cv are:</span>

<span class="sd">        * None, to use the default 5-fold cross validation,</span>
<span class="sd">        * integer, to specify the number of folds in a (Stratified) KFold,</span>
<span class="sd">        * An object to be used as a cross-validation generator,</span>
<span class="sd">        * An iterable yielding train, test splits.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and y is</span>
<span class="sd">        either binary or multiclass, `StratifiedKFold` is used. In all other</span>
<span class="sd">        cases, `KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. note::</span>
<span class="sd">           A larger number of split will provide no benefits if the number</span>
<span class="sd">           of training samples is large enough. Indeed, the training time</span>
<span class="sd">           will increase. ``cv`` is not used for model evaluation but for</span>
<span class="sd">           prediction.</span>

<span class="sd">    stack_method : {&#39;auto&#39;, &#39;predict_proba&#39;, &#39;decision_function&#39;, &#39;predict&#39;}, \</span>
<span class="sd">            default=&#39;auto&#39;</span>
<span class="sd">        Methods called for each base estimator. It can be:</span>

<span class="sd">        * if &#39;auto&#39;, it will try to invoke, for each estimator,</span>
<span class="sd">          `&#39;predict_proba&#39;`, `&#39;decision_function&#39;` or `&#39;predict&#39;` in that</span>
<span class="sd">          order.</span>
<span class="sd">        * otherwise, one of `&#39;predict_proba&#39;`, `&#39;decision_function&#39;` or</span>
<span class="sd">          `&#39;predict&#39;`. If the method is not implemented by the estimator, it</span>
<span class="sd">          will raise an error.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        The number of jobs to run in parallel all `estimators` `fit`.</span>
<span class="sd">        `None` means 1 unless in a `joblib.parallel_backend` context. -1 means</span>
<span class="sd">        using all processors. See Glossary for more details.</span>

<span class="sd">    passthrough : bool, default=False</span>
<span class="sd">        When False, only the predictions of estimators will be used as</span>
<span class="sd">        training data for `final_estimator`. When True, the</span>
<span class="sd">        `final_estimator` is trained on the predictions as well as the</span>
<span class="sd">        original training data.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        Verbosity level.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    classes_ : ndarray of shape (n_classes,)</span>
<span class="sd">        Class labels.</span>

<span class="sd">    estimators_ : list of estimators</span>
<span class="sd">        The elements of the estimators parameter, having been fitted on the</span>
<span class="sd">        training data. If an estimator has been set to `&#39;drop&#39;`, it</span>
<span class="sd">        will not appear in `estimators_`.</span>

<span class="sd">    named_estimators_ : :class:`~sklearn.utils.Bunch`</span>
<span class="sd">        Attribute to access any fitted sub-estimators by name.</span>

<span class="sd">    final_estimator_ : estimator</span>
<span class="sd">        The classifier which predicts given the output of `estimators_`.</span>

<span class="sd">    stack_method_ : list of str</span>
<span class="sd">        The method used by each base estimator.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    When `predict_proba` is used by each estimator (i.e. most of the time for</span>
<span class="sd">    `stack_method=&#39;auto&#39;` or specifically for `stack_method=&#39;predict_proba&#39;`),</span>
<span class="sd">    The first column predicted by each estimator will be dropped in the case</span>
<span class="sd">    of a binary classification problem. Indeed, both feature will be perfectly</span>
<span class="sd">    collinear.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Wolpert, David H. &quot;Stacked generalization.&quot; Neural networks 5.2</span>
<span class="sd">       (1992): 241-259.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_iris</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.svm import LinearSVC</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import LogisticRegression</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.preprocessing import StandardScaler</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.pipeline import make_pipeline</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.ensemble import StackingClassifier</span>
<span class="sd">    &gt;&gt;&gt; X, y = load_iris(return_X_y=True)</span>
<span class="sd">    &gt;&gt;&gt; estimators = [</span>
<span class="sd">    ...     (&#39;rf&#39;, RandomForestClassifier(n_estimators=10, random_state=42)),</span>
<span class="sd">    ...     (&#39;svr&#39;, make_pipeline(StandardScaler(),</span>
<span class="sd">    ...                           LinearSVC(random_state=42)))</span>
<span class="sd">    ... ]</span>
<span class="sd">    &gt;&gt;&gt; clf = StackingClassifier(</span>
<span class="sd">    ...     estimators=estimators, final_estimator=LogisticRegression()</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span>
<span class="sd">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span>
<span class="sd">    ...     X, y, stratify=y, random_state=42</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; clf.fit(X_train, y_train).score(X_test, y_test)</span>
<span class="sd">    0.9...</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">stack_method</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">passthrough</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">final_estimator</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">stack_method</span><span class="o">=</span><span class="n">stack_method</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">passthrough</span><span class="o">=</span><span class="n">passthrough</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_final_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clone_final_estimator</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_classifier</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;&#39;final_estimator&#39; parameter should be a classifier. Got </span><span class="si">{}</span><span class="s2">&quot;</span>
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the estimators.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where `n_samples` is the number of samples and</span>
<span class="sd">            `n_features` is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            Target values.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Sample weights. If None, then samples are equally weighted.</span>
<span class="sd">            Note that this is supported only if all underlying estimators</span>
<span class="sd">            support sample weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_classification_targets</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_le</span><span class="o">.</span><span class="n">classes_</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="s1">&#39;final_estimator_&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">predict_params</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict target for X.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        **predict_params : dict of str -&gt; obj</span>
<span class="sd">            Parameters to the `predict` called by the `final_estimator`. Note</span>
<span class="sd">            that this may be used to return uncertainties from some estimators</span>
<span class="sd">            with `return_std` or `return_cov`. Be aware that it will only</span>
<span class="sd">            accounts for uncertainty in the final estimator.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_pred : ndarray of shape (n_samples,) or (n_samples, n_output)</span>
<span class="sd">            Predicted targets.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">predict_params</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_le</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="s1">&#39;final_estimator_&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict class probabilities for X using</span>
<span class="sd">        `final_estimator_.predict_proba`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        probabilities : ndarray of shape (n_samples, n_classes) or \</span>
<span class="sd">            list of ndarray of shape (n_output,)</span>
<span class="sd">            The class probabilities of the input samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="nd">@if_delegate_has_method</span><span class="p">(</span><span class="n">delegate</span><span class="o">=</span><span class="s1">&#39;final_estimator_&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Predict decision function for samples in X using</span>
<span class="sd">        `final_estimator_.decision_function`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        decisions : ndarray of shape (n_samples,), (n_samples, n_classes), \</span>
<span class="sd">            or (n_samples, n_classes * (n_classes-1) / 2)</span>
<span class="sd">            The decision function computed the final estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return class labels or probabilities for X for each estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where `n_samples` is the number of samples and</span>
<span class="sd">            `n_features` is the number of features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_preds : ndarray of shape (n_samples, n_estimators) or \</span>
<span class="sd">                (n_samples, n_classes * n_estimators)</span>
<span class="sd">            Prediction outputs for each estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sk_visual_block_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># If final_estimator&#39;s default changes then this should be</span>
        <span class="c1"># updated.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">final_estimator</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">final_estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_sk_visual_block_</span><span class="p">(</span><span class="n">final_estimator</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">StackingRegressor</span><span class="p">(</span><span class="n">RegressorMixin</span><span class="p">,</span> <span class="n">_BaseStacking</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stack of estimators with a final regressor.</span>

<span class="sd">    Stacked generalization consists in stacking the output of individual</span>
<span class="sd">    estimator and use a regressor to compute the final prediction. Stacking</span>
<span class="sd">    allows to use the strength of each individual estimator by using their</span>
<span class="sd">    output as input of a final estimator.</span>

<span class="sd">    Note that `estimators_` are fitted on the full `X` while `final_estimator_`</span>
<span class="sd">    is trained using cross-validated predictions of the base estimators using</span>
<span class="sd">    `cross_val_predict`.</span>

<span class="sd">    .. versionadded:: 0.22</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;stacking&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    estimators : list of (str, estimator)</span>
<span class="sd">        Base estimators which will be stacked together. Each element of the</span>
<span class="sd">        list is defined as a tuple of string (i.e. name) and an estimator</span>
<span class="sd">        instance. An estimator can be set to &#39;drop&#39; using `set_params`.</span>

<span class="sd">    final_estimator : estimator, default=None</span>
<span class="sd">        A regressor which will be used to combine the base estimators.</span>
<span class="sd">        The default regressor is a `RidgeCV`.</span>

<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy used in</span>
<span class="sd">        `cross_val_predict` to train `final_estimator`. Possible inputs for</span>
<span class="sd">        cv are:</span>

<span class="sd">        * None, to use the default 5-fold cross validation,</span>
<span class="sd">        * integer, to specify the number of folds in a (Stratified) KFold,</span>
<span class="sd">        * An object to be used as a cross-validation generator,</span>
<span class="sd">        * An iterable yielding train, test splits.</span>

<span class="sd">        For integer/None inputs, if the estimator is a classifier and y is</span>
<span class="sd">        either binary or multiclass, `StratifiedKFold` is used. In all other</span>
<span class="sd">        cases, `KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. note::</span>
<span class="sd">           A larger number of split will provide no benefits if the number</span>
<span class="sd">           of training samples is large enough. Indeed, the training time</span>
<span class="sd">           will increase. ``cv`` is not used for model evaluation but for</span>
<span class="sd">           prediction.</span>

<span class="sd">    n_jobs : int, default=None</span>
<span class="sd">        The number of jobs to run in parallel for `fit` of all `estimators`.</span>
<span class="sd">        `None` means 1 unless in a `joblib.parallel_backend` context. -1 means</span>
<span class="sd">        using all processors. See Glossary for more details.</span>

<span class="sd">    passthrough : bool, default=False</span>
<span class="sd">        When False, only the predictions of estimators will be used as</span>
<span class="sd">        training data for `final_estimator`. When True, the</span>
<span class="sd">        `final_estimator` is trained on the predictions as well as the</span>
<span class="sd">        original training data.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        Verbosity level.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    estimators_ : list of estimator</span>
<span class="sd">        The elements of the estimators parameter, having been fitted on the</span>
<span class="sd">        training data. If an estimator has been set to `&#39;drop&#39;`, it</span>
<span class="sd">        will not appear in `estimators_`.</span>

<span class="sd">    named_estimators_ : :class:`~sklearn.utils.Bunch`</span>
<span class="sd">        Attribute to access any fitted sub-estimators by name.</span>


<span class="sd">    final_estimator_ : estimator</span>
<span class="sd">        The regressor to stacked the base estimators fitted.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] Wolpert, David H. &quot;Stacked generalization.&quot; Neural networks 5.2</span>
<span class="sd">       (1992): 241-259.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.datasets import load_diabetes</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.linear_model import RidgeCV</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.svm import LinearSVR</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.ensemble import RandomForestRegressor</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.ensemble import StackingRegressor</span>
<span class="sd">    &gt;&gt;&gt; X, y = load_diabetes(return_X_y=True)</span>
<span class="sd">    &gt;&gt;&gt; estimators = [</span>
<span class="sd">    ...     (&#39;lr&#39;, RidgeCV()),</span>
<span class="sd">    ...     (&#39;svr&#39;, LinearSVR(random_state=42))</span>
<span class="sd">    ... ]</span>
<span class="sd">    &gt;&gt;&gt; reg = StackingRegressor(</span>
<span class="sd">    ...     estimators=estimators,</span>
<span class="sd">    ...     final_estimator=RandomForestRegressor(n_estimators=10,</span>
<span class="sd">    ...                                           random_state=42)</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span>
<span class="sd">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span>
<span class="sd">    ...     X, y, random_state=42</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; reg.fit(X_train, y_train).score(X_test, y_test)</span>
<span class="sd">    0.3...</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">n_jobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">passthrough</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">final_estimator</span><span class="o">=</span><span class="n">final_estimator</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">stack_method</span><span class="o">=</span><span class="s2">&quot;predict&quot;</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">passthrough</span><span class="o">=</span><span class="n">passthrough</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_final_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clone_final_estimator</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="n">RidgeCV</span><span class="p">())</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_regressor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;&#39;final_estimator&#39; parameter should be a regressor. Got </span><span class="si">{}</span><span class="s2">&quot;</span>
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">final_estimator_</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Fit the estimators.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where n_samples is the number of samples and</span>
<span class="sd">            n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            Target values.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Sample weights. If None, then samples are equally weighted.</span>
<span class="sd">            Note that this is supported only if all underlying estimators</span>
<span class="sd">            support sample weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">warn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return the predictions for X for each estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training vectors, where `n_samples` is the number of samples and</span>
<span class="sd">            `n_features` is the number of features.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_preds : ndarray of shape (n_samples, n_estimators)</span>
<span class="sd">            Prediction outputs for each estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sk_visual_block_</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># If final_estimator&#39;s default changes then this should be</span>
        <span class="c1"># updated.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">final_estimator</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">final_estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final_estimator</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_sk_visual_block_</span><span class="p">(</span><span class="n">final_estimator</span><span class="p">)</span>
</pre></div>

              </div>
              
              
              <div class='prev-next-bottom'>
                

              </div>
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../_static/js/index.d3f166471bb80abb5163.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2021, Boston Consulting Group (BCG).<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>